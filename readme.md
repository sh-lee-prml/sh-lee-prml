## Sang-Hoon Lee
I will join the Department of Software and Computer Engineering at Ajou University as an Assistant Professor in Mar. 2024 ([SAIL, Speech AI Lab.](https://sites.google.com/view/speechailab)). I'm currently a postdoctoral researcher in AI Research Center, Korea University, Seoul, South Korea. I received the Ph.D. degree in the Department of Brain and Cognitive Engineering, Korea University in 2023. In March 2016, I started my integrated M.S.&Ph.D. in [Pattern Recognition & Machine Learning (PRML) Lab](http://pr.korea.ac.kr) at the Korea University in Seoul, Korea, under the supervision of [Seong-Whan Lee](http://pr.korea.ac.kr/sub2_1.php?code=LSW).

- E-mail: sanghoonlee@ajou.ac.kr, sh_lee@korea.ac.kr
- Google Scholar: [Link](https://scholar.google.com/citations?user=HDzlBm0AAAAJ&hl=en)
- Speech AI Lab. (SAIL): [Link](https://sites.google.com/view/speechailab)
- PRML Speech Team (Supervisor: [Seong-Whan Lee](http://pr.korea.ac.kr/sub2_1.php?code=LSW)): [Link](https://prml-lab-speech-team.github.io/demo/)

### üëÄ Research Interests 
- Speech Synthesis (2019-, [**HierSpeech++**](https://github.com/sh-lee-prml/HierSpeechpp), **DDDM-VC**)
- Neural Vocoder (2021-, [**PeriodWave**](https://github.com/sh-lee-prml/PeriodWave), [**PeriodWave-Turbo**](https://github.com/sh-lee-prml/PeriodWave), **Fre-GAN**, **Fre-GAN2**)
- Neural Audio Codec (2024-)
- Singing Voice Synthesis (2022-, **MIDI-Voice**, **HiddenSinger**)
- Speech-to-Speech Translation (2023-, **TranSentence**)
- Brain-Computer Interface (2019-2020, **[Brain-to-Speech System](https://brain-to-speech.github.io/demo/BTS)**)
- Reinforcement Learning (2017-2018, AI Curling Robot **[Curly](https://www.youtube.com/watch?v=71S8qpmU6VA)**)

### ‚úî News
- 2024.09: One paper has been accepted to Neural Networks ([HiddenSinger](https://arxiv.org/abs/2306.06814)). This project was funded by Netmarble AI Center, Netmarble Corp. in 2022.
- 2024.04: One paper has been accepted to TASLP ([DiffProsody](https://github.com/hsoh0306/DiffProsody))
- 2024.01: One paper has been accepted to ICASSPW 2024 ([LIMMITS'24](https://sites.google.com/view/limmits24/home?authuser=0), ICASSP SP Grand Challenges)  
- 2023.12: One paper has been accepted to TASLP ([Fre-Painter](https://ieeexplore.ieee.org/document/10381805))
- 2023.12: Two papers have been accepted to ICASSP 2024 (TranSentence, MIDI-Voice)
- 2023.12: One paper has been accepted to AAAI 2024 ([DDDM-VC](https://arxiv.org/abs/2305.15816)) 
- 2023.11: We release [HierSpeech++](https://github.com/sh-lee-prml/HierSpeechpp), Zero-shot Speech Synthesis models for Zero-shot TTS, Zero-shot VC, and Speech Super-resolution. [[Demo]](https://sh-lee-prml.github.io/HierSpeechpp-demo/) [[Code]](https://github.com/sh-lee-prml/HierSpeechpp) [[Gradio]](https://huggingface.co/spaces/LeeSangHoon/HierSpeech_TTS)

<!-- 
- 2023.05: We release [Decoupled Denoising Diffusion Models (DDDMs) and DDDM-VC](https://arxiv.org/abs/2305.15816) for robust voice conversion system. We also extend DDDMs to DDDM-TTS by utilzing the pre-trained DDDM-VC and Text-to-Vec (TTV) systems. 
- 2023.05: Two Paper have been accepted to Interspeech 2023 (Diff-HierVC, HierVST)
- 2022.11: Two paper have been accepted to [JKAIA2022](http://aiassociation.kr/UploadData/Editor/Conference/202211/AB25A5D8158240D0A0D04C593F48DF0D.pdf)
- 2022.09: One paper has been accepted to NeurIPS 2022 (HierSpeech)
- 2022.03: One paper has been accepted to IEEE TASLP (DCVC)
- 2022.03: One paper has been accepted to ICPR 2022 (StyleVC) 
- 2022.01: Three paper have been accepted to ICASSP 2022 (Fre-GAN 2, EmoQ-TTS, PVAE-TTS) -->



## üéâ Publications
### Arxiv
- [Accelerating High-Fidelity Waveform Generation via Adversarial Flow Matching Optimization](https://arxiv.org/abs/2408.08019), **S.-H. Lee**, H.-Y. Choi, and S.-W. Lee, 2024. (Under Review) [[Code]](https://github.com/sh-lee-prml/PeriodWave)
- [PeriodWave: Multi-Period Flow Matching for High-Fidelity Waveform Generation](https://arxiv.org/abs/2408.07547), **S.-H. Lee**, H.-Y. Choi, and S.-W. Lee, 2024. (Under Review) [[Code]](https://github.com/sh-lee-prml/PeriodWave)
- [HierSpeech++: Bridging the Gap between Semantic and Acoustic Representation by Hierarchical Variational Inference for Zero-shot Speech Synthesis](https://arxiv.org/abs/2311.12454), **S.-H. Lee**, H.-Y. Choi, S.-B. Kim, and S.-W. Lee, 2023. (Under Review) [[Demo]](https://sh-lee-prml.github.io/HierSpeechpp-demo/) [[Code]](https://github.com/sh-lee-prml/HierSpeechpp) [[Gradio]](https://huggingface.co/spaces/LeeSangHoon/HierSpeech_TTS)
- [DurFlex-EVC: Duration-Flexible Emotional Voice Conversion with Parallel Generation](https://arxiv.org/abs/2401.08095), H.-S. Oh, **S.-H. Lee**, D.-H. Cho, and S.-W. Lee, 2024. (Under Review) [[Demo]](https://prml-lab-speech-team.github.io/durflex/) [[Code]](https://github.com/hs-oh-prml/DurFlexEVC)

### 2024
- [HiddenSinger: High-Quality Singing Voice Synthesis via Neural Audio Codec and Latent Diffusion Models](https://arxiv.org/abs/2306.06814), J.-S. Hwang, **S.-H. Lee**, and S.-W. Lee, **Neural Networks**, 2024 [[Demo]](https://jisang93.github.io/hiddensinger-demo/)
- [DiffProsody: Diffusion-based Latent Prosody Generation for Expressive Speech Synthesis with Prosody Conditional Adversarial Training](https://arxiv.org/abs/2307.16549), H.-S. Oh, **S.-H. Lee**, and S.-W. Lee, **TASLP**, 2024 [[Demo]](https://prml-lab-speech-team.github.io/demo/DiffProsody/) [[Code]](https://github.com/hsoh0306/DiffProsody)
- [Cross-lingual Text-to-Speech via Hierarchical Style Transfer](https://sites.google.com/view/limmits24/home?authuser=0), **S.-H. Lee**, H.-Y. Choi, and S.-W. Lee, **ICASSPW**, 2024. 
- [Audio Super-resolution with Robust Speech Representation Learning of Masked Autoencoder](https://ieeexplore.ieee.org/document/10381805), S.-B. Kim, **S.-H. Lee**, H.-Y. Choi, S.-W. Lee, **TASLP**, 2024.
- [TranSentence: Speech-to-Speech Translation via Language-agnostic Sentence-level Speech Encoding without Language-parallel Data](https://ieeexplore.ieee.org/abstract/document/10447331), S.-B. Kim, **S.-H. Lee**, and S.-W. Lee, **ICASSP**, 2024.
- [MIDI-Voice: Expressive Zero-shot Singing Voice Synthesis via MIDI-driven Priors](https://ieeexplore.ieee.org/abstract/document/10447981/), D.-M. Byun, **S.-H. Lee**, J.-S. Hwang, and S.-W. Lee, **ICASSP**, 2024.
- [DDDM-VC: Decoupled Denoising Diffusion Models with Disentangled Representation and Prior Mixup for Verified Robust Voice Conversion](https://arxiv.org/abs/2305.15816), H.-Y. Choi*, **S.-H. Lee***, and S.-W. Lee, **AAAI**, 2024. [[Demo]](https://hayeong0.github.io/DDDM-VC-demo/) [[Code]](https://github.com/hayeong0/DDDM-VC) [[Poster]](https://github.com/sh-lee-prml/sh-lee-prml/blob/main/DDDM-VC_poster.pdf)

### 2023 
- [HierVST: Hierarchical Adaptive Zero-shot Voice Style Transfer](https://www.isca-speech.org/archive/interspeech_2023/lee23i_interspeech.html), **S.-H. Lee***, H.-Y. Choi*, H.-S. Oh, and S.-W. Lee, **Interspeech**, 2023. (Oral) [[Arxiv]](https://arxiv.org/abs/2307.16171) [[Demo]](https://hiervst.github.io/)
- [Diff-HierVC: Diffusion-based Hierarchical Voice Conversion with Robust Pitch Generation and Masked Prior for Zero-shot Speaker Adaptation](https://www.isca-speech.org/archive/interspeech_2023/choi23d_interspeech.html), H.-Y. Choi, **S.-H. Lee**, and S.-W. Lee, **Interspeech**, 2023. (Oral) [[Demo]](https://diff-hiervc.github.io/) [[Code]](https://github.com/hayeong0/Diff-HierVC)
- [PauseSpeech: Natural Speech Synthesis via Pre-trained Language Model and Pause-based Prosody Modeling](https://arxiv.org/abs/2306.07489), J.-S. Hwang, **S.-H. Lee**, and S.-W. Lee, **ACPR**, 2023. [[Demo]](https://jisang93.github.io/pausespeech-demo/)
### 2022
- [HierSpeech: Bridging the Gap between Text and Speech by Hierarchical Variational Inference using Self-supervised Representations for Speech Synthesis](https://openreview.net/pdf?id=awdyRVnfQKX), **S.-H. Lee**, S.-B. Kim, J.-H. Lee, E. Song, M.-J. Hwang, and S.-W. Lee, **NeurIPS**, 2022. [[OpenReview]](https://openreview.net/forum?id=awdyRVnfQKX) [[Demo]](https://sh-lee-prml.github.io/hierspeech-demo/) [[Poster]](https://github.com/sh-lee-prml/sh-lee-prml/blob/main/HierSpeech_poster_final.pdf)
- [Duration Controllable Voice Conversion via Phoneme-based Information Bottleneck](https://ieeexplore.ieee.org/abstract/document/9729483), **S.-H. Lee**, H.-R. Noh, W. Nam, and S.-W. Lee, **IEEE TASLP**, 2022. (2022-JCR-IF: 5.4, JIF PERCENTILE TOP 8.10%)
- StyleVC: Non-Parallel Voice Conversion with Adversarial Style Generalization, I. Hwang, **S.-H. Lee**, and S.-W. Lee, **ICPR**, 2022. [[Demo]](https://prml-lab-speech-team.github.io/demo/insun-hwang/StyleVC/) [[Code]](https://github.com/intory89/StyleVC)
- [Fre-GAN 2: Fast and Efficient Frequency-consistent Audio Synthesis](https://ieeexplore.ieee.org/document/9746675), **S.-H. Lee**, J.-H. Kim, G.-E. Lee, and S.-W. Lee, **ICASSP**, 2022. [[Demo]](https://prml-lab-speech-team.github.io/demo/FreGAN2/) [[Code]](https://github.com/prml-lab-speech-team/demo/tree/master/FreGAN2/code)
- [PVAE-TTS: Progressively Style Adaptive Text-to-Speech via Progressive Variaional Autoencoder](https://ieeexplore.ieee.org/document/9747388),	J.-H. Lee, **S.-H. Lee**, J.-H. Kim, and S.-W. Lee,  **ICASSP**, 2022. [[Demo]](https://prml-lab-speech-team.github.io/demo/PVAE-TTS/)
- [EmoQ-TTS: Emotion Intensity Quantization for Fine-Grained Controllable Emotional Text-to-Speech](https://ieeexplore.ieee.org/document/9747098),	C.-B. Im, **S.-H. Lee**, and S.-W. Lee, **ICASSP**, 2022. [[Demo]](https://prml-lab-speech-team.github.io/demo/EmoQ-TTS/)


### 2021
- [VoiceMixer: Adversarial Voice Style Mixup](https://proceedings.neurips.cc/paper/2021/hash/0266e33d3f546cb5436a10798e657d97-Abstract.html), **S.-H. Lee**, J.-H. Kim, H. Chung, and S.-W. Lee, **NeurIPS**, 2021. [[Demo]](https://anonymous-speech.github.io/voicemixer/)
- [Multi-SpectroGAN: High-Diversity and High-Fidelity Spectrogram Generation with Adversarial Style Combination for Speech Synthesis](https://arxiv.org/abs/2012.07267), **S.-H. Lee**, H.-W. Yoon, H.-R. Noh, J.-H. Kim, and S.-W. Lee, **AAAI**, 2021. [[Demo]](https://anonymsg.github.io/MSG/Demo/index.html)
- [GC-TTS: Few-shot Speaker Adaptation with Geometric Constraints](https://ieeexplore.ieee.org/abstract/document/9658830), J.-H. Kim, **S.-H. Lee**, J.-H. Lee, H.-G. Jung, and S.-W. Lee, **SMC**, 2021.
- [Fre-GAN: Adversarial Frequency-consistent Audio Synthesis](https://arxiv.org/abs/2106.02297), J.-H. Kim, **S.-H. Lee**, J.-H. Lee, and S.-W. Lee, **Interspeech**, 2021.  
- [Reinforce-Aligner: Reinforcement Alignment Search for Robust End-to-End Text-to-Speech](https://arxiv.org/abs/2106.02830), H. Chung, **S.-H. Lee**, and S.-W. Lee, **Interspeech**, 2021.  

### ~2020
- [Audio Dequantization for High Fidelity Audio Generation in Flow-based Neural Vocoder](https://arxiv.org/abs/2008.06867), H.-W. Yoon, **S.-H. Lee**, H.-R. Noh, and S.-W. Lee, **Interspeech**, 2020.  
- [Learning Machines Can Curl - Adaptive deep reinforcement learning enables the robot Curly to win against human players in an icy world](https://nips.cc/Conferences/2019/ScheduleMultitrack?event=15442), [D.-O. Won](https://sites.google.com/view/aiml-hallym/people/professor?authuser=0), **S.-H. Lee**, K.-R. Muller, and S.-W. Lee, **NeurIPS 2019 Demonstration Track**, 2019. [[Video]](https://www.youtube.com/watch?v=71S8qpmU6VA) [[Poster]](https://github.com/sh-lee-prml/sh-lee-prml/blob/main/NeurIPS2019_poster.pdf)

### Patents (KR)
- "METHOD AND SYSTEM FOR SYNTHESIZING SPEECH," 10-2663162, 29, Apr., 2024.
- "METHOD TO TRANSFORM VOICE," 10-2439022, 29, Aug., 2022.
- "METHOD AND APPARTUS FOR VOICE CONVERSION BY USING NEURAL NETWORK," 10-2340486, 14, Dec., 2021.
- "SYSTEM AND METHOD FOR CURLING SWEEPING CONTROL," 10-2257358, 21, May, 2021.
- "APPARATUS AND METHOD FOR RECOMMENDATION OF CURLING GAME STRATEGY USING DEEP LEARNING," 10-2045567, 11, Nov., 2019.
- "APPARATUS AND METHOD FOR DELIVERY AND SWEEPING AT CURLING GAME," 10-1948713, 11, Feb., 2019.


### ‚ú® Educations
**2016.03-2023.02**: Integrated M.S.&Ph.D, Dept. of Brain and Cognitive Engineering, Korea University

**2012.03-2016.02**: B.S, Dept. of Life Science, Dongguk University

### üéÅ Awards and Services
**Reviewer**: NeurIPS, ICLR, ICML, AAAI, ICASSP, IEEE/ACM Transactions on Audio, Speech, and, Language Processing 

**2022.02.25**: Paper Award (Multi-SpectroGAN: High-Diversity and High-Fidelity Spectrogram Generation with Adversarial Style Combination for Speech Synthesis), Korea University

### üéôInvited Talks
**2024.06.25**: Fake Audio Detection, Ajou University. 

**2024.06.07**: Speech Synthesis, Ï†ú2ÌöåAIÏúµÌï©ÏõåÌÅ¨Ïàç, Ajou University.

**2024.05.24**: Speech Language Model for Generative AI, [KSCS2024](https://cogsci.or.kr/kscs2024/)

**2023.08.18**: Towards Unified Speech Synthesis for Text-to-Speech and Voice Conversion, [Deepbrain AI](https://www.deepbrain.io/)

**2023.08.11**: Towards Unified Speech Synthesis for Text-to-Speech and Voice Conversion, [Workshop on Brain and Artificial Intelligence 2023](https://brainedusociety.kr/Conference/ConferenceView.asp?AC=2&CODE=CI20230701&CpPage=91#CONF)

**2023.06.20**: HierSpeech: Bridging the Gap between Text and Speech by Hierarchical Variational Inference using Self-supervised Representations for Speech Synthesis, [Top Conference Session in KCC2023](https://www.kiise.or.kr/conference/kcc/2023/)

**2022.08.19**: VoiceMixer: Adversarial Voice Style Mixup, [AIGS Symposium 2022](https://aigs.kr/default/customer/customer_01.php?com_board_basic=read_form&topmenu=5&left=1&com_board_idx=24&com_board_id=2)

**2022.07.01**: VoiceMixer: Adversarial Voice Style Mixup, [Top Conference Session in KCC2022](https://www.kiise.or.kr/conference/kcc/2022/)

**2021.12.02**: Voice Conversion, Netmarble

**2021.07.29**: Speech Synthesis and Voice Conversion, Neosapience

